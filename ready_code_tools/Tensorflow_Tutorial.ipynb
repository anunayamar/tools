{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtaining the first image from the mnist dataset\n",
    "batch_xs, batch_ys = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 784), (1, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xs.shape, batch_ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADZxJREFUeJzt3X+MFPUZx/HPI21NFP4Qq+T40VITqKkkQnIxakhjtTYW\nSAD/UPhHqqTXREtK0pgaalITbcTG1tR/GqnF0qaF1viLwFmDxEg1tREuVVELWAPxyMlVMXJoFMWn\nf+zQnHrz3WV3ZmeO5/1KLrc7z87Oc3v3uZnd+fE1dxeAeE6rugEA1SD8QFCEHwiK8ANBEX4gKMIP\nBEX4gaAIPxAU4QeC+kI3F2ZmHE4IlMzdrZXHdbTmN7OrzGyPmb1mZrd08lwAusvaPbbfzCZI2ivp\nSkmDkp6XtNzdX0nMw5ofKFk31vwXSXrN3V9392OSNkla3MHzAeiiTsI/TdIbo+4PZtM+xcz6zGyn\nme3sYFkAClb6B37uvk7SOonNfqBOOlnzH5Q0Y9T96dk0AONAJ+F/XtIsM/uamX1J0jJJm4tpC0DZ\n2t7sd/ePzeyHkp6QNEHSend/ubDOAJSq7V19bS2M9/xA6bpykA+A8YvwA0ERfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaC6\nOkQ3Tj1Tp05N1i+//PLc2oIFC5LzXnvttcn6wMBA28seGRlJzhsBa34gKMIPBEX4gaAIPxAU4QeC\nIvxAUIQfCKqjUXrNbL+kEUnHJX3s7r1NHs8ovTUze/bsZP3GG29M1leuXJmsn3HGGbm1skeIvvnm\nm3Nr99xzT6nLrlKro/QWcZDPt9z9rQKeB0AXsdkPBNVp+F3Sk2a2y8z6imgIQHd0utk/390Pmtm5\nkraZ2b/dfcfoB2T/FPjHANRMR2t+dz+YfR+W9Iiki8Z4zDp37232YSCA7mo7/GZ2pplNOnFb0nck\n7S6qMQDl6mSzf4qkR8zsxPP82d3/VkhXAErXdvjd/XVJFxbYC0pw/fXXJ+t33XVXsj558uQi20GN\nsKsPCIrwA0ERfiAowg8ERfiBoAg/EBSX7h4Hli9fnqzfeuutubXzzz8/OW/Zp9U+/fTTubWenp7k\nvLNmzSq6HYzCmh8IivADQRF+ICjCDwRF+IGgCD8QFOEHguro0t0nvTAu3T2miy++OFl/9tln237u\n005L/3//4IMPkvXh4eFkvdmlvXfs2JFbu+SSS5LzPv7448l6MxMmTOho/vGq1Ut3s+YHgiL8QFCE\nHwiK8ANBEX4gKMIPBEX4gaA4n78GFi5cmKx3cizGnXfemaxv27YtWX/qqafaXrYk3X777bm16667\nLjlvs59769atbfWEBtb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU0/38ZrZe0iJJw+4+J5s2WdJf\nJM2UtF/SNe7+TnltntoGBgY6mn/v3r25tTVr1nT03J268ML8UdynTZvW0XP39/d3NH90raz5fy/p\nqs9Mu0XSdnefJWl7dh/AONI0/O6+Q9Lhz0xeLGlDdnuDpCUF9wWgZO2+55/i7kPZ7TclTSmoHwBd\n0vGx/e7uqWvzmVmfpL5OlwOgWO2u+Q+ZWY8kZd9zr/Lo7uvcvdfde9tcFoAStBv+zZJWZLdXSHqs\nmHYAdEvT8JvZRkn/kPR1Mxs0s5WS1kq60sz2Sfp2dh/AOMJ1+2vg9NNPT9ZXrVqVrG/atCm3Njg4\n2FZPRTl+/HhurdO/vZkzZybrVf/sVeG6/QCSCD8QFOEHgiL8QFCEHwiK8ANBcenuGvjwww+T9bvv\nvrtLnXze3Llzk/ULLrggWTfL3+t07Nix5LzPPPNMsv7uu+8m60hjzQ8ERfiBoAg/EBThB4Ii/EBQ\nhB8IivADQXFKb3CTJk1K1h944IFkfcmS9LVbP/roo9za6tWrk/Ped999yTrGxim9AJIIPxAU4QeC\nIvxAUIQfCIrwA0ERfiAozucP7uqrr07Wm+3Hb+bee+/NrbEfv1qs+YGgCD8QFOEHgiL8QFCEHwiK\n8ANBEX4gqKb7+c1svaRFkobdfU427TZJ35f03+xha9y9v6wm0b5HH300Wb/iiitKXX5/P38WddXK\nmv/3kq4aY/o97j43++I3DIwzTcPv7jskHe5CLwC6qJP3/KvM7EUzW29mZxXWEYCuaDf8v5F0nqS5\nkoYk/TLvgWbWZ2Y7zWxnm8sCUIK2wu/uh9z9uLt/Ium3ki5KPHadu/e6e2+7TQIoXlvhN7OeUXeX\nStpdTDsAuqWVXX0bJV0m6ctmNijpZ5IuM7O5klzSfkk/KLFHACXguv2ngEWLFuXWNm/enJy32e//\n/fffT9Znz56drA8NDSXrKB7X7QeQRPiBoAg/EBThB4Ii/EBQhB8Iil1948DZZ5+drO/enX+M1bnn\nnpucd8+ePcn6DTfckKw/99xzyTq6j119AJIIPxAU4QeCIvxAUIQfCIrwA0ERfiAohuiugTlz5iTr\nDz74YLJ+zjnntL3sZvvp2Y9/6mLNDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcT5/F0yaNClZ37p1\na7J+6aWXtr3s9957L1lfu3Ztsj5jxoxkfeHChcm6Wf6p5WX/7aWWvWvXruS8S5cuLbqdruF8fgBJ\nhB8IivADQRF+ICjCDwRF+IGgCD8QVNPz+c1shqQ/SJoiySWtc/dfm9lkSX+RNFPSfknXuPs75bVa\nX1OnTk3Wmw2TPW/evCLb+ZRmxxjccccdpS1bqnY//5EjR3JrAwMDpS57PGhlzf+xpB+7+zckXSzp\nJjP7hqRbJG1391mStmf3AYwTTcPv7kPuPpDdHpH0qqRpkhZL2pA9bIOkJWU1CaB4J/We38xmSpon\n6Z+Sprj7UFZ6U423BQDGiZav4WdmEyU9JGm1ux8Z/V7O3T3vuH0z65PU12mjAIrV0prfzL6oRvD/\n5O4PZ5MPmVlPVu+RNDzWvO6+zt173b23iIYBFKNp+K2xiv+dpFfd/VejSpslrchur5D0WPHtAShL\n01N6zWy+pL9LeknSJ9nkNWq87/+rpK9IOqDGrr7DTZ5r3J7SmxomOzVEttR8mOwyd3mldrWVvWxJ\nGhoayq2NjIwk53377bc7WvbKlStza3v37u3oueus1VN6m77nd/dnJOU92RUn0xSA+uAIPyAowg8E\nRfiBoAg/EBThB4Ii/EBQDNHdomXLluXWJk6c2MVOTs4LL7yQrHe6v/v+++9P1vft25dbO3r0aHLe\nTvfzI401PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExRDdBThw4ECyPn369GS92e9g48aNyXp/f39u\nbcuWLcl5m51Tj/GHIboBJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFDs5wdOMeznB5BE+IGgCD8QFOEH\ngiL8QFCEHwiK8ANBNQ2/mc0ws6fM7BUze9nMfpRNv83MDprZv7KvBeW3C6AoTQ/yMbMeST3uPmBm\nkyTtkrRE0jWSjrr73S0vjIN8gNK1epBP0xF73H1I0lB2e8TMXpU0rbP2AFTtpN7zm9lMSfMk/TOb\ntMrMXjSz9WZ2Vs48fWa208x2dtQpgEK1fGy/mU2U9LSkn7v7w2Y2RdJbklzS7Wq8NbihyXOw2Q+U\nrNXN/pbCb2ZflLRF0hPu/qsx6jMlbXH3OU2eh/ADJSvsxB4zM0m/k/Tq6OBnHwSesFTS7pNtEkB1\nWvm0f76kv0t6SdIn2eQ1kpZLmqvGZv9+ST/IPhxMPRdrfqBkhW72F4XwA+XjfH4ASYQfCIrwA0ER\nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgml7As2BvSTow6v6Xs2l1VNfe\n6tqXRG/tKrK3r7b6wK6ez/+5hZvtdPfeyhpIqGtvde1Lord2VdUbm/1AUIQfCKrq8K+rePkpde2t\nrn1J9NauSnqr9D0/gOpUveYHUJFKwm9mV5nZHjN7zcxuqaKHPGa238xeykYernSIsWwYtGEz2z1q\n2mQz22Zm+7LvYw6TVlFvtRi5OTGydKWvXd1GvO76Zr+ZTZC0V9KVkgYlPS9pubu/0tVGcpjZfkm9\n7l75PmEz+6ako5L+cGI0JDP7haTD7r42+8d5lrv/pCa93aaTHLm5pN7yRpb+nip87Yoc8boIVaz5\nL5L0mru/7u7HJG2StLiCPmrP3XdIOvyZyYslbchub1Djj6frcnqrBXcfcveB7PaIpBMjS1f62iX6\nqkQV4Z8m6Y1R9wdVryG/XdKTZrbLzPqqbmYMU0aNjPSmpClVNjOGpiM3d9NnRpauzWvXzojXReMD\nv8+b7+5zJX1X0k3Z5m0teeM9W5121/xG0nlqDOM2JOmXVTaTjSz9kKTV7n5kdK3K126Mvip53aoI\n/0FJM0bdn55NqwV3P5h9H5b0iBpvU+rk0IlBUrPvwxX383/ufsjdj7v7J5J+qwpfu2xk6Yck/cnd\nH84mV/7ajdVXVa9bFeF/XtIsM/uamX1J0jJJmyvo43PM7MzsgxiZ2ZmSvqP6jT68WdKK7PYKSY9V\n2Mun1GXk5ryRpVXxa1e7Ea/dvetfkhao8Yn/fyT9tIoecvo6T9IL2dfLVfcmaaMam4EfqfHZyEpJ\nZ0vaLmmfpCclTa5Rb39UYzTnF9UIWk9Fvc1XY5P+RUn/yr4WVP3aJfqq5HXjCD8gKD7wA4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8A1lmMGTZttgoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18d3c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = batch_xs\n",
    "X = X.reshape((28, 28))\n",
    "plt.gray()\n",
    "plt.imshow(X)\n",
    "print (batch_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computation graph contains computations and different computations are related to each other with edges\n",
    "#called tensor, thus the name is tensor flow\n",
    "\n",
    "#Whatever, we are defining in this cell is going to be a part of the computation graph. The graph tells \n",
    "#how things are executed\n",
    "\n",
    "#Placeholder is nothing, but a placeholder. It will be supplied with an actual value during training.\n",
    "#You can view it as placeholder that accepts a flotating point 784 dimensional value.\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "#tf.nn.softmax applies softmax activation function to Wx + b, as over here we have 10 dimension (classes)\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is going to be our actual output\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is our loss function, over here we have used cross entropy loss function\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is how we would minimize the loss function.\n",
    "#This also takes care of backpropogation\n",
    "#Basically train_step contains the complete computation graph, including the wx+b, softmax calculation, loss, gradient etc..\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#session is used, and it feeds the computation graph to CPU or GPU for execution\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only after running tf.global_variables_initializer() in a session will your variables hold the values \n",
    "#you told them to hold when you declare them (tf.Variable(tf.zeros(...))\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In this we run the loop 1000 times, each loop takes random 100 examples from the mnist dataset.\n",
    "#Then do the training, calculates the loss, perform gradient descent, and updates the weights\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    #train_step is the computation graph feed to sess.run\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.argmax returns the index of the max value in the tensor along the specified axis, \n",
    "#correct_prediction contains a tensor of boolean\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9225\n"
     ]
    }
   ],
   "source": [
    "print (sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
